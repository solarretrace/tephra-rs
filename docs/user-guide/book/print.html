<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Tephra User&#x27;s Guide</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><a href="design_goals.html">Design Goals</a></li><li class="chapter-item expanded affix "><li class="part-title">User Guide</li><li class="chapter-item expanded "><a href="getting_started.html"><strong aria-hidden="true">1.</strong> Getting Started</a></li><li class="chapter-item expanded "><a href="terminology.html"><strong aria-hidden="true">2.</strong> Terminology</a></li><li class="chapter-item expanded "><a href="create_the_scanner.html"><strong aria-hidden="true">3.</strong> Create the Scanner</a></li><li class="chapter-item expanded "><a href="create_the_lexer.html"><strong aria-hidden="true">4.</strong> Create the Lexer</a></li><li class="chapter-item expanded "><a href="create_the_parser.html"><strong aria-hidden="true">5.</strong> Create the Parser</a></li><li class="chapter-item expanded "><a href="handling_errors.html"><strong aria-hidden="true">6.</strong> Handling Errors</a></li><li class="chapter-item expanded "><a href="wrapping_up.html"><strong aria-hidden="true">7.</strong> Wrapping Up</a></li><li class="chapter-item expanded "><a href="debugging.html"><strong aria-hidden="true">8.</strong> Debugging</a></li><li class="chapter-item expanded affix "><li class="part-title">Reference</li><li class="chapter-item expanded "><a href="spans.html"><strong aria-hidden="true">9.</strong> Spans</a></li><li class="chapter-item expanded "><a href="lexer.html"><strong aria-hidden="true">10.</strong> Lexer</a></li><li class="chapter-item expanded "><a href="combinators.html"><strong aria-hidden="true">11.</strong> Combinators</a></li><li class="chapter-item expanded "><a href="parse_errors.html"><strong aria-hidden="true">12.</strong> Parse Errors</a></li><li class="chapter-item expanded "><a href="parse_results.html"><strong aria-hidden="true">13.</strong> Parse Results</a></li><li class="chapter-item expanded affix "><li class="part-title">Combinator Reference</li><li class="chapter-item expanded "><a href="primitive_combinators.html"><strong aria-hidden="true">14.</strong> Primitive Combinators</a></li><li class="chapter-item expanded "><a href="repetition_combinators.html"><strong aria-hidden="true">15.</strong> Repetition Combinators</a></li><li class="chapter-item expanded "><a href="join_combinators.html"><strong aria-hidden="true">16.</strong> Join Combinators</a></li><li class="chapter-item expanded "><a href="control_combinators.html"><strong aria-hidden="true">17.</strong> Control Combinators</a></li><li class="chapter-item expanded "><a href="section_combinators.html"><strong aria-hidden="true">18.</strong> Section Combinators</a></li><li class="chapter-item expanded affix "><li class="part-title">Developer Reference</li><li class="chapter-item expanded "><a href="project_layout.html"><strong aria-hidden="true">19.</strong> Project Layout</a></li><li class="chapter-item expanded "><a href="design_notes.html"><strong aria-hidden="true">20.</strong> Design Notes</a></li><li class="chapter-item expanded "><a href="building.html"><strong aria-hidden="true">21.</strong> Building</a></li><li class="chapter-item expanded "><a href="testing.html"><strong aria-hidden="true">22.</strong> Testing</a></li><li class="chapter-item expanded "><a href="tracing.html"><strong aria-hidden="true">23.</strong> Tracing</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Tephra User&#x27;s Guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tephra-design-goals"><a class="header" href="#tephra-design-goals">Tephra Design Goals</a></h1>
<p>Tephra is a Rust library for designing parsers.</p>
<p>Tephra began is a simple collection of text-consuming functions, and has evolved over time into a more complex and featurefull library. The following features were gradually introduced according to the reasoning layed out below:</p>
<ol>
<li>Text references are based on <code>&amp;'t str</code>, not <code>&amp;mut &amp;'t str</code>.</li>
</ol>
<p>The original design of Tephra used <code>&amp;mut &amp;'t str</code>, and had a problem if the parse ever had to return to a prior state, in that you had to make copies of the text reference. The inevitable need to make copies removes any real efficiency or conceptual gains this design might have had, so using shared references is more consistent and simpler overall.</p>
<ol start="2">
<li>Use <code>std::Result</code>.</li>
</ol>
<p>Tephra's parse results are built upon <code>std::Result</code>. The hope is that this would simplify extending the library, as one could rely on existing well-understood result methods, but experience with the library indicates that this may not be very valuable; most parser result handling is fairly specialized, even when there are overlaps in functionality, the generic names in <code>std::Result</code> don't aid in clarifying the code.</p>
<ol start="3">
<li>Distinguish between parser functions and parser combinators.</li>
</ol>
<p>As a parser combinator library, it is possible to make primitive parsers into combinators that return parse functions. This leads to a bit of syntax noise in the form of extra function calls (<code>one(Token)()</code>, rather than <code>one(Token)</code>), but it would make the code more uniform. In practice, parsers are usually invoked implicitely, so it is easier to name the function directly, rather than require it be returned from another function. Combinators are thus only 'invoked' if there are configuration arguments that need to be evaluated.</p>
<ol start="4">
<li>
<p>Parsers implement <code>FnMut</code>.</p>
</li>
<li>
<p>Use separate lexer and parser phases.</p>
</li>
<li>
<p>Scanner emits new positions relative to base, not position diffs.</p>
</li>
</ol>
<p>This is needed to support tabstops in ColumnMetrics.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>Tephra parsers use a combination of builtin types and user-defined types to construct recursive-descent parsers. Different aspects of the parse are religated to different components of the library. The typical process for implementing a full-featured parser looks like this:</p>
<ol>
<li>
<p>Define a token type.</p>
</li>
<li>
<p>Define a Scanner type that matches the tokens in text. The scanner should use a ColumnMetrics implementor to measure the tokens.</p>
</li>
<li>
<p>Define a set of parsers which will parse the grammar of your input.</p>
</li>
<li>
<p>If you're defining recursive structures, you may want to implement a set of structure-matchers to simplify the grammar.</p>
</li>
<li>
<p>Create a Lexer from your Scanner and ColumnMetrics, invoke the parser by passing in the lexer, then transform the output into your desired result type.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="terminology"><a class="header" href="#terminology">Terminology</a></h1>
<h3 id="tokens"><a class="header" href="#tokens">Tokens</a></h3>
<p>Tokens are emitted by the Lexer and Scanner impls, and are defined according to the associated type on Scanner:</p>
<pre><code>type Token: Display + Debug + Clone + PartialEq + Send + Sync + 'static;
</code></pre>
<p>The <code>Display</code> impl should be what is shown for a token in error messages, while the <code>Debug</code> impl is what appears in traces.</p>
<h3 id="lexer-scanner-and-columnmetrics"><a class="header" href="#lexer-scanner-and-columnmetrics">Lexer, Scanner, and ColumnMetrics</a></h3>
<p>In order to begin parsing with tephra, a <code>Lexer</code> must be created. The <code>Lexer</code> is a builtin struct that wraps a <code>Scanner</code> impl with the appropriate <code>Token</code> type. The <code>Lexer</code> extends the <code>Scanner</code> by holding the source text, column metrics, and automatically creating spans and filtering tokens.</p>
<p>The <code>Lexer::next</code> method will invoke <code>Scanner::next</code>, which is expected to produce the next scanned token and a measure of how far to advance any spans that include it. To properly implement a <code>Scanner</code>, one should use the provided <code>ColumnMetrics</code> to compute span advancements (<code>Pos</code>), and any scanning state should be internal to the <code>Scanner</code>, such as nesting depth or delimitted context flags. It may be worthwhile to track additional scanning state to make the scanner more efficient, e.g., by changing the priority of checking for different tokens based on what was previously scanned.</p>
<h3 id="parsing-functions-and-combinators"><a class="header" href="#parsing-functions-and-combinators">Parsing functions and combinators</a></h3>
<p>Parsers are functions which take in a <code>Lexer</code> and return a <code>ParseResult</code>. Parser combinators take in a set of configuration arguments and return a parser closure. Parsers and combinators should be generic over the <code>ColumnMetrics</code> and <code>Scanner</code> implementations, and additionally any sub-parsers or result types returned by them.</p>
<p>Tephra provides a suite of primitive parsers and combinators which are suitable for composing into more complicated parsers.</p>
<h3 id="parse-results"><a class="header" href="#parse-results">Parse results</a></h3>
<p>The <code>ParseResult</code> type returned by a parser is an alias for <code>Result&lt;Success&lt;...&gt;, Failure&lt;...&gt;&gt;</code>, which is generic over the lifetime of the source text, the <code>ColumnMetrics</code> and <code>Scanner</code>, and the value created by a successful parse. The <code>Success</code> type holds the parsed value and the <code>Lexer</code> state after finishing the parse. The <code>Failure</code> type holds the error value and the <code>Lexer</code> state after failing the parse. In a typical scenerio, the lexer is passed into a parser and extracted from its result to continue a sequence of parses. To parse alternatives instead of sequences, it makes more sense to clone the lexer, pass it into each possibility, and return the lexer of the option that succeeds.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="create-the-scanner"><a class="header" href="#create-the-scanner">Create the Scanner</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="create-the-lexer"><a class="header" href="#create-the-lexer">Create the Lexer</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="create-the-parser"><a class="header" href="#create-the-parser">Create the Parser</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="handling-errors"><a class="header" href="#handling-errors">Handling Errors</a></h1>
<p>There's a saying in software development called the <a href="https://en.wikipedia.org/wiki/Ninety-ninety_rule">ninety-ninety</a> rule, and when it comes to designing a quality parser library, it seems that ninety percent of your effort will be spent on trying to create useful error messages. This is a survey of the error handling techniques I've tried and why they don't work.</p>
<h2 id="incremental-call-stack"><a class="header" href="#incremental-call-stack">Incremental Call Stack</a></h2>
<p>The simplest way to report errors is to simply churn along, and when you encounter a parse which can't proceed, dump the current parse location. The first problem with this is that you have almost no context about what was supposed to be parsed, so this is almost entirely useless. To fix that, you might try to collect a 'stack trace', which seems to help at first. You get error that look something like this:</p>
<pre><code>parse failure at byte 126: &quot;goodgoodbadbad...&quot;
                                    ^
.. during a parse of RULE C
.. during a parse of RULE B
.. during a parse of RULE A
</code></pre>
<p>What you'll probably learn pretty quickly is that is also unhelpful. Sure, you have some idea of where in your code the error occurred, but there are other problems. First, parse rules often attempt multiple things, so it is natural that they fail, and thus you'll only ever be told a rule fails if its last possible attempt fails. Secondly, most of the rules beyond the first listed are useless because they end up telling you vague things like this:</p>
<pre><code>parse failure at byte 126: &quot;goodgoodbadbad...&quot;
                                    ^
.. during a parse of expression
.. during a parse of statement
.. during a parse of document
</code></pre>
<p>... and clearly you can see how unhelpful that is. Often, most of your parses are going to be expressions, statements, documents, and such things. And on the bottom-most level, all you know is that none of the attempted possibilities worked.</p>
<h2 id="spans"><a class="header" href="#spans">Spans</a></h2>
<p>The next innovation is spans. Instead of just tracking the current parse location, we track spans of text. The first obvious advantage to this is that we'll often have misplaced tokens, and now when an unexpected token occurs, we can highlight the whole thing, giving a clear outline of which token is unexpected. It's a small thing, but it helps. Ideally, we really want the ability to highlight more than a single token though.</p>
<p>This should allow us to get errors that look marginally better:</p>
<pre><code>parse failure: unexpected token at bytes 126-129: &quot;goodgoodbadbad...&quot;
                                                           ^^^
</code></pre>
<p>To do that, we need the ability to join spans together. There are two obvious ways to do this: (1) Every parse emits a span, and then we manually join them to create larger spans; (2) Every parse takes in a span, and attaches any newly parsed tokens to the end automatically. I call (1) explicit joins, and (2) implicit joins.</p>
<p>I recommend starting with the implicit join idea, because more often than not, we want to join spans, and conveniently enough, our lexer has to track the current parse location anyway, so it may as well track the back end of the span and produce the spans we want on demand. This is arguably more efficient as well, because we don't need to actually calculate joined spans after every parse, we just advance the current position (which we would be doing anyway.)</p>
<p>The problem with implicit joins is figuring out how and when to break them up. By default, every span will extend all the way back to the start of the text. Lexer errors are fairly straightforward to fix though:</p>
<ul>
<li>
<p>If a token is unexpected, just highlight the span of the last parsed token.</p>
</li>
<li>
<p>If a EOF was encountered, just highlight the current parse position.</p>
</li>
</ul>
<p>Outside of those, there is no obvious and automatic way to determine where spans should break.</p>
<h1 id="additional-parse-failure-contexts"><a class="header" href="#additional-parse-failure-contexts">Additional parse failure contexts</a></h1>
<p>In addition to the above highlightings, it is often beneficial to know what was expected, and more importantly, <em>why</em> it was expected. If a parse fails, we know what parser was running and what it is expecting to find. If some prefix of an unambiguous parse succeeds, then we also know why we're expecting something. </p>
<p>A parse can fail for many reasons, and some of those failures should be ignored depending on context. </p>
<pre><code>It is a successful match
It is an attempt to match
    .. because a prefix of it was successful
        1. Use `atomic` to delineate the section
        2. Why are we parsing?
        3. What failed? -&gt; in ParseError
        4. What was expected. -&gt; in ParseError

    .. because a validation condition failed
        1. use `section` to delineate the section.
        2. Why are we parsing?
        3. What failed? -&gt; in ParseError
        4. What was expected. -&gt; in ParseError
It is not an attempt to match
    .. because no prefix was successful
        1. use `maybe` to delineate the section
    .. because a validation condition failed
        1. use `maybe` to delineate the section
</code></pre>
<h2 id="general-purpose-parsers"><a class="header" href="#general-purpose-parsers">General purpose parsers</a></h2>
<p>Going forward, one of the central constraints is that a given parser shouldn't know anything about its span context -- the amount of span that should be reported if it fails -- unless it is failing with a lexer error. A parser doesn't really know if it parsing an entire document or a small part of one, so parsers should be as general as possible, and as much of the error handling should be pushed as high up in the grammar as possible.</p>
<p>Another big idea is that there are such things as 'bounded' and 'unbounded' parses, determined by whether a parser is effectively recursive or not. It is much easier to push error handling for bounded parsers lower in the grammar because they take on a fewer variety of forms and the details of what was supposed to be present are much clearer. Conversely, unbounded parses can traverse through many intermediate rules, and it is often much less helpful to know what those rules were as opposed to what is bracketting those rules. So in essence, we usually want to phrase errors arrising from failures in unbounded rules in terms of the bounded rules that introduce or bracket them.</p>
<p>Furthermore, in order to keep our parsers general purpose, we want to minimize the amount of special context handling within a parser. For example, the <code>bracket</code> combinator is not going to consider any of its arguments as inherently special; it should be suitable for parsing <code>abc</code> just as easily as <code>[b]</code>.</p>
<h2 id="when-to-clone-the-lexer"><a class="header" href="#when-to-clone-the-lexer">When to clone the lexer.</a></h2>
<p>Clone the lexer whenever you make and overly-general parse. This will allow <code>atomic</code> to work correctly.</p>
<h2 id="sections-and-recovery"><a class="header" href="#sections-and-recovery">Sections and Recovery</a></h2>
<p>Every time we're about to introduce an 'open bracket' or delimitted parse, we want to break off into a new span. </p>
<p>Speaking of brackets, when we have a failure within a delimitted rule, it often makes sense to log an error, advance to the next delimiter, and continue on to look for further errors.</p>
<h2 id="error-relavance-and-validation"><a class="header" href="#error-relavance-and-validation">Error relavance and validation</a></h2>
<p>Parsers frequently attempt a sequence of sub-parsers, and perhaps naively, one would expect to swallow up any intermediate errors and move on to try the next thing. This is simple to implement and it works well enough, unless none of the sub-parsers succeed and you 'drop out' at the bottom: at this point, the parse which failed is entirely ambiguous, because they <em>all</em> failed.</p>
<p>And frequently, the problem is not due to an obvious grammatical error. All of the correct tokens may be in place, but one of the attempts may have failed in performing some necessary conversion on it, leaving the parser to swallow up that error and go on to do everything else which has no hope of succeeding.</p>
<p>The broader point here is that there is a scaled notion of relevance when multiple sub-parses are performed. In the case that both parses would succeed, the most relevant one is the first to be applied (as one would expect and/or desire for sequential code... If we're parsing concurrently, this question might need a more serious answer.)</p>
<p>If only one of the two succeeds, the successful one is more relevant. However, if both parses fail, the naive process above results in the last one being the most relevant, and that is often <em>not</em> what we want, unless none of the rules are gramattically correct. We could try adding a flag to the error type so we can decide whether to return or continue (or perhaps more wildly: simulate &quot;throwing exceptions&quot;), but we should make sure not to handle this decision at the sub-parser's call site, because there may be successful parses following a conversion failure, and we want successful parses to take priority.</p>
<p>Another thing to bear in mind is that grammatical errors only have a few possible error states: unexpected tokens, unexpected end-of-text, unrecognized tokens. All other errors signify that only valid tokens were produced and consumed, so they must be conversion errors.</p>
<p>As an addendum to all of the above, a lot of these kinds of headaches can be avoided by delaying any validation operations as long as possible. You might parse the entire input to validate its grammar and capture all values as text, then do a second pass to convert text values into semantically meaningful values. By doing this, you ensure that all parsers have consistent behavior, because they can only fail due to grammatical errors. The downside of this is that it becomes difficult to compose parsers, because you have to forbid calling into anything that does validation. It also means you can't easily do context-sensitive parsing where you make decisions based on the value of a previous parse, but that's probably something to avoid for other reasons.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wrapping-up"><a class="header" href="#wrapping-up">Wrapping Up</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debugging"><a class="header" href="#debugging">Debugging</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="spans-1"><a class="header" href="#spans-1">Spans</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lexer"><a class="header" href="#lexer">Lexer</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="combinators"><a class="header" href="#combinators">Combinators</a></h1>
<p>One of tephra's design goals is to minimize the number of parser combinators supplied. This is to the benefit of the user, as it is far less likely to use the wrong combinator when only a few options are available, and any of the rarer parses that would behave in an exceptional manner immediately stand out due to the use of special handling at the parse site. Moreover it is easier to understand a smaller set of combinators, which makes it that much easier to understand when they are being used incorrectly, or when a manually written parser is doing what a simple combinator would do.</p>
<p>Another consequence of minimizing the set of combinators is that tephra doesn't demand a compositional parser writing style, as would be expected of a parser combinator library in a functional language. It is expected for the user to write imperative code for handling errors and introducing optimizations and tracing into their parsers.</p>
<p>Every combinator provided by tephra is either assumed to be useful for a wide variety of situations, or obvious and trivial in what it does. This is a surprisingly hard standard to meet, so we'll go over each combinator to explain what it is useful for, as well as a broader picture of parsing various common things to show how they are used in practice. We'll also cover some of the control methods available on the parse result types, as they cover some of the functionality that a traditional combinator library would provide.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parse-errors"><a class="header" href="#parse-errors">Parse Errors</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parse-results-1"><a class="header" href="#parse-results-1">Parse Results</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="primitive-combinators"><a class="header" href="#primitive-combinators">Primitive Combinators</a></h1>
<h2 id="primitive-token-combinators"><a class="header" href="#primitive-token-combinators">Primitive (Token) Combinators</a></h2>
<h3 id="empty"><a class="header" href="#empty"><code>empty</code></a></h3>
<p>A mostly useless parser with a trivial implementation. Returns a successful parse of nothing.</p>
<h3 id="fail"><a class="header" href="#fail"><code>fail</code></a></h3>
<h3 id="end_of_text"><a class="header" href="#end_of_text"><code>end_of_text</code></a></h3>
<p>A simple and useful combinator. Successfully parses only if there is no more text to process, which is a useful way to ensure everything has been parsed. Often used to validate the final result of all parsing, or as a terminator for a repeating parse.</p>
<h3 id="one"><a class="header" href="#one"><code>one</code></a></h3>
<p>Probably the most useful combinator provided. Constructs a parser the matches a single token. This is usually the first step in any parse.</p>
<h3 id="any"><a class="header" href="#any"><code>any</code></a></h3>
<p>An obvious generalization of <code>one</code>, which will successfully parse one of any of the given tokens. Less useful than <code>one</code>, because you probably end up matching on the result (but you could also do that with <code>Lexer::peek</code> without advancing the lexer state.) This is more useful when you want to dynamically match related tokens, such as when using <code>bracket_dynamic</code>.</p>
<p>Example:</p>
<p>In atma-script, this is only used in one place: to dynamically match single and double quotes on strings.</p>
<pre><code>let string_close = move |lexer, tok| match tok {
        StringOpenSingle =&gt; one(StringCloseSingle)(lexer),
        StringOpenDouble =&gt; one(StringCloseDouble)(lexer),
        _ =&gt; unreachable!(),
    };

bracket_dynamic(
    any(&amp;[StringOpenSingle, StringOpenDouble]),
    text(one(StringText)),
    string_close)
</code></pre>
<p>Without <code>any</code>, the solution would be to attempt each parse seperately, or to write the implementations of these manually.</p>
<h3 id="seq"><a class="header" href="#seq"><code>seq</code></a></h3>
<p>Another obvious generalization of <code>one</code>, which will successfully parse the given sequence of tokens. This is often used with <code>exact</code>, but in many situations, a proper <code>Scanner</code> impl will obviate the need for this.</p>
<p>Example:</p>
<p>In atma-script, this is only used once to parse color hex codes. because the <code>HexDigits</code> token overlaps with identifiers, the <code>Hash</code> token changes the scanning mode to avoid parsing idents until a <code>HexDigits</code> is found.</p>
<pre><code>text(exact(seq(&amp;[
    AtmaToken::Hash,
    AtmaToken::HexDigits])))
</code></pre>
<p>Alternatively, the Scanner could just consume the <code>Hash</code> and <code>HexDigits</code> as a single token. So it ends up being a very minor trade-off between scanner complexity and parser complexity.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="repetition-combinators"><a class="header" href="#repetition-combinators">Repetition Combinators</a></h1>
<h3 id="repeat"><a class="header" href="#repeat"><code>repeat</code></a></h3>
<h3 id="repeat_until"><a class="header" href="#repeat_until"><code>repeat_until</code></a></h3>
<h3 id="repeat_collect"><a class="header" href="#repeat_collect"><code>repeat_collect</code></a></h3>
<h3 id="repeat_collect_until"><a class="header" href="#repeat_collect_until"><code>repeat_collect_until</code></a></h3>
<h3 id="intersperse"><a class="header" href="#intersperse"><code>intersperse</code></a></h3>
<h3 id="intersperse_until"><a class="header" href="#intersperse_until"><code>intersperse_until</code></a></h3>
<h3 id="intersperse_collect"><a class="header" href="#intersperse_collect"><code>intersperse_collect</code></a></h3>
<h3 id="intersperse_collect_until"><a class="header" href="#intersperse_collect_until"><code>intersperse_collect_until</code></a></h3>
<h2 id="option-combinators"><a class="header" href="#option-combinators">Option Combinators</a></h2>
<h3 id="maybe"><a class="header" href="#maybe"><code>maybe</code></a></h3>
<p>This combinator is sometimes useful when parsing something that is entirely optional. They key word being 'entirely': if any part of the parse suceeds, but not the entire parse, this will succeed with <code>None</code>. The behavior of <code>atomic</code> is often more useful, but <code>maybe</code> is simpler and makes sense for smaller parses, such as looking for extra optional tokens. </p>
<p>Example:</p>
<p>In StmaScript, trailing commas are accepted in array expressions. The <code>maybe</code> combinator allows the parse to tolerate this extra bit of notation:</p>
<pre><code>bracket(
    one(OpenBracket),
    left(
        intersperse_collect(0, None,
            expr,
            one(Comma)),
        maybe(one(Comma))),
    one(CloseBracket))
    (lexer)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="join-combinators"><a class="header" href="#join-combinators">Join Combinators</a></h1>
<h3 id="left-right-both-bracket"><a class="header" href="#left-right-both-bracket"><code>left</code>, <code>right</code>, <code>both</code>, <code>bracket</code></a></h3>
<p>These are common and useful combinators that allow you to perform a sequence of parses, capturing specific parts of the output. Often used to parse prefixes, postfixes, delimiters, brackets, etc.</p>
<h3 id="bracket_dynamic"><a class="header" href="#bracket_dynamic"><code>bracket_dynamic</code></a></h3>
<p>This is an occasionally useful generalization of <code>bracket</code>, that passes the output of the first parser to the third parser. This can be used to match closing brackets with opening brackets. When the bracket is a token, it often makes more sense to push a token context in the <code>Scanner</code> to ensure the correct ending token is encountered (such as with comments or strings.)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="control-combinators"><a class="header" href="#control-combinators">Control Combinators</a></h1>
<h2 id="control-combinators-1"><a class="header" href="#control-combinators-1">Control Combinators</a></h2>
<h3 id="filter_with"><a class="header" href="#filter_with"><code>filter_with</code></a></h3>
<p>This combinator is not very useful, but it is a more general form of the sometimes-useful <code>exact</code> combinator. It allows you to temporarily set the lexer filters during a parse so that you can selectively ignore tokens.</p>
<h3 id="exact"><a class="header" href="#exact"><code>exact</code></a></h3>
<p>This combinator is occasionally useful, but the implementation is quite general. It disables all lexer filters during a parse, allowing you to take manual control over the exact tokens consumed. This is useful if you want to do something like parse two tokens without any whitespace between them. (A potentially preferred alternative to this would to redesign the <code>Scanner</code> to match the combined tokens as a new token.)</p>
<h3 id="discard"><a class="header" href="#discard"><code>discard</code></a></h3>
<p>A mostly useless parser with a trivial implementation. Discards the parse result and converts it to <code>()</code>.</p>
<h3 id="text"><a class="header" href="#text"><code>text</code></a></h3>
<p>This combinator substitutes a successful parse result with the text it was parsed from. This is commonly wrapped around token combinators to extract the text of the token that was matched.</p>
<h3 id="require_if"><a class="header" href="#require_if"><code>require_if</code></a></h3>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section-combinators"><a class="header" href="#section-combinators">Section Combinators</a></h1>
<h3 id="section"><a class="header" href="#section"><code>section</code></a></h3>
<h3 id="spanned"><a class="header" href="#spanned"><code>spanned</code></a></h3>
<p>This should be one of your most-used combinators. It captures the span of a parse, and is incredibly useful for describing errors from a parse.</p>
<h3 id="atomic"><a class="header" href="#atomic"><code>atomic</code></a></h3>
<p>This combinator is useful to attempt a parse when the parse call tree is determined by a prefix. Basically, as soon as any part of the given parser succeeds, it is an error for the remainder of the parse to fail.</p>
<p>The <code>atomic</code> combinator can sometimes cause headaches if you improperly clone (or fail to clone) the lexer. For example, if you parse a more general token at the beginning of the parse and fail if it doesn't satisfy some constraint (such parsing a identifier and succeeding only if it matches a specific keyword), then the <code>atomic</code> wrapper will make this parse fail if <em>any</em> version of the general parse is successful (so it will fail on any identifier match.) To avoid this, you always want to clone the lexer before making more general parses than necessary, and then fail by returning the original.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="project-layout"><a class="header" href="#project-layout">Project Layout</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tephra-developer-design-notes"><a class="header" href="#tephra-developer-design-notes">Tephra Developer Design Notes</a></h1>
<h2 id="use-t-str-not-mut-t-str"><a class="header" href="#use-t-str-not-mut-t-str">Use <code>&amp;'t str</code>, not <code>&amp;mut &amp;'t str</code>.</a></h2>
<p>This makes it easier to back up in case of a failure. This only applies to a combined lexer/parser.</p>
<p>Different parser designs may be able to accomodate different data formats. In order to build a streaming parser, the lexer won't be able to return slices into the source, as the lexeme borrows from the lexer's internal buffer, rather than the external source text buffer.</p>
<h2 id="use-stdresult"><a class="header" href="#use-stdresult">Use <code>std::Result</code>.</a></h2>
<h2 id="if-a-function-takes-extra-args-return-a-parser"><a class="header" href="#if-a-function-takes-extra-args-return-a-parser">If a function takes extra args, return a parser.</a></h2>
<h2 id="if-a-function-takes-no-extra-args-it-is-the-parser"><a class="header" href="#if-a-function-takes-no-extra-args-it-is-the-parser">If a function takes no extra args, it is the parser.</a></h2>
<h2 id="use-fnmut"><a class="header" href="#use-fnmut">Use <code>FnMut</code></a></h2>
<h2 id="use-stderrorerror-for-failure-source"><a class="header" href="#use-stderrorerror-for-failure-source">Use <code>std::error::Error</code> for failure source.</a></h2>
<h2 id="do-not-boxown-all-parse-errors"><a class="header" href="#do-not-boxown-all-parse-errors">Do not box/own all parse errors.</a></h2>
<h2 id="impl-partialeq-on-results-for-testing"><a class="header" href="#impl-partialeq-on-results-for-testing">Impl <code>PartialEq</code> on results for testing.</a></h2>
<h2 id="return-value-lexer-on-success"><a class="header" href="#return-value-lexer-on-success">Return value, lexer on success.</a></h2>
<h2 id="dont-use-generics-for-column-metrics"><a class="header" href="#dont-use-generics-for-column-metrics">Don't use generics for column metrics.</a></h2>
<h2 id="join-spans-by-default-explicitely-separate-them"><a class="header" href="#join-spans-by-default-explicitely-separate-them">Join spans by default, explicitely separate them.</a></h2>
<p>Spans are joined extremely frequently, so it is much simpler to only specify when they should be separated. The lexer should track both its current position and the position of the last unconsumed text. This will enable lexer reuse without cloning, and allow spans to be joined implicitely.
The Lexer::next method returns the span of the most recent token on success, and on error it returns the span of unconsumed text.</p>
<h2 id="return-lexer-reason-source-on-failure"><a class="header" href="#return-lexer-reason-source-on-failure">Return lexer, reason, source on failure.</a></h2>
<h2 id="separate-lexer-and-parser"><a class="header" href="#separate-lexer-and-parser">Separate lexer and parser.</a></h2>
<p>This allows us to easily filter lexed tokens, i.e., to remove whitespace or comments. It also allows injecting tokens, i.e., to specify indentation levels, or to analyze comments using a separate parser stream. </p>
<p>Without a dedicated lexer, all intermediate syntactical structure must be filtered or created inline, and it becomes difficult to separate and analyze.</p>
<pre><code>result
span
lexer
combinator
    text
    token
primitive
    comment
    float
    integer
    list
    string
</code></pre>
<h2 id="scanner-holds-state"><a class="header" href="#scanner-holds-state">Scanner holds state</a></h2>
<p>The scanner must hold state to allow processing escaped tokens. Nested comments, matching quotes, etc., can be lexed as escaped text or as language tokens, and the scanner needs to know what the open/escape is. So whenever a scanner produces an escape token, it records that state until the corresponding close is produced.</p>
<h2 id="scanner-outputs-option"><a class="header" href="#scanner-outputs-option">Scanner outputs Option</a></h2>
<p>If the scanned text is empty, it is obvious that there is no token to scan, and if the scanner returns None, then there is no token to match the text. The main problem with this is in detecting <em>why</em> there is no match if text remains, which could be a function of the scanner state.</p>
<p>In practice, this is probably not a problem, because a parser should know whether the scanner is entering such a state, and if the parse fails, we should be able to determine why. This probably means that you can't use simple combinators for e.g., both strings and bracketed tokens, but you would usually want escaped tokens to be processed in their own parsers anyway.</p>
<p>This also means the scanner doesn't need a dedicated error type, and that parse errors arising from the scanner won't need to be boxed, which is simple and more efficient.</p>
<h2 id="scan-for-any-token-or-a-specific-token"><a class="header" href="#scan-for-any-token-or-a-specific-token">Scan for any token or a specific token?</a></h2>
<p>Scanning for specific tokens would probably be more efficient and will make scanners easier to write. Token patterns can overlap, and the same text can be matched by multiple tokens, depending on what the parser requested.</p>
<p>On the other hand, those ambiguities don't seem relevant in practice. Scanning for any token allows for cleaner iteration, and most importantly, efficiently scanning ahead to a sentinal token. It also allows for more complex filtering capabilities.</p>
<h1 id="lexer-filtering-and-span-construction"><a class="header" href="#lexer-filtering-and-span-construction">Lexer filtering and span construction</a></h1>
<p>The lexer output should be filterable and contain full-constructed spans before any parser code works on it.</p>
<h2 id="lexer-trait-or-lexer-struct"><a class="header" href="#lexer-trait-or-lexer-struct">Lexer trait or lexer struct?</a></h2>
<p>The Lexer could be a trait requiring Iterator over the lexemes. This would allow iterator combinators to do filtering and transformation of the lexer output, as well as allow arbitrary parsers to transform the lexer on demand. On the other hand, it is likely that combinator errors would get difficult to analyze, as the lexer would have many type variables. This also makes it almost impossible to interact with the lexer state during parsing. At a minumum every iterator would need to be clonable so allow backtracking in case of a failed parse.</p>
<p>The lexer could present a struct interface. This is problematic in that it strongly constrains what the lexer is allowed to do. It doesn't allow parsers to transform the lexer without including stateful operations on the lexer. Fortunately, there is not a whole lot that the typical lexer will need to do: filter whitespace, backtrack, push tokens into the stream, ... Most other options can be handled in the parser code.</p>
<h1 id="lexer-conversions"><a class="header" href="#lexer-conversions">Lexer conversions</a></h1>
<p>There's a bit of wasted effort in not doing value production in the lexer. Lexing a number or escaped string is redundant with converting it to the associated value. However, there are several ways to avoid this problem, each with different tradeoffs.</p>
<h2 id="1-non-trival-lexer-tokens"><a class="header" href="#1-non-trival-lexer-tokens">1. Non-trival lexer tokens.</a></h2>
<p>The lexer can produce the data in a single pass and emit it with the token. This means token matching becomes more complex, so we'll need to separate Tokens carrying values from TokenTypes, which are used in matching.</p>
<h2 id="2-data-in-the-lexeme"><a class="header" href="#2-data-in-the-lexeme">2. Data in the lexeme.</a></h2>
<p>The lexer always produces a value and stores it in the lexeme. This requires the parser to know which tokens produce values and of which type, so that they may be retrieved. This could involve wrapping low-level parsers in data-extractor combinators, which could be confusing. (And doing it automatically would essentially look the same as #1.)</p>
<h2 id="3-no-data-conversions-in-the-lexer"><a class="header" href="#3-no-data-conversions-in-the-lexer">3. No data conversions in the lexer.</a></h2>
<p>The lexer always produces a simple token and its span. There is some redundant effort in calculating data conversions, but it can be done using normal data conversion combinators. Additionally, if the data is unused (eg., part of a fallible parse,) this may be the most efficient approach.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building"><a class="header" href="#building">Building</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing"><a class="header" href="#testing">Testing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tracing"><a class="header" href="#tracing">Tracing</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            var socket = new WebSocket("ws://localhost:3000/__livereload");
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->

        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
